3. Image Classification mnist
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import numpy as np

train_data_dir = 'Datasets/mnist-jpg/train'
test_data_dir = 'Datasets/mnist-jpg/test'

# Image data generator for training data used for rescaling pixel values
train_datagen = ImageDataGenerator(
rescale=1.0/255  # Rescales the pixel values of the images to the range [0, 1]
)

# Image data generator for testing data
test_datagen = ImageDataGenerator(
rescale=1.0/255  # Rescales the pixel values of the images to the range [0, 1]
)

# Create data generators
train_batch_size = 10000  # Sets the batch size for the training data
train_generator = train_datagen.flow_from_directory(
    train_data_dir,  # Specifies the directory containing the training data
    target_size=(28, 28),  # Resizes the images to 28x28 pixels
    batch_size=train_batch_size,  # Sets the batch size for the training data
    class_mode='categorical',   # Specifies that the labels should be one-hot encoded
    color_mode='grayscale',  # Specifies that the images are grayscale
    shuffle=True,  # Shuffles the training data
)

# Load test data without labels (class_mode=None)
test_batch_size = 2000  # Sets the batch size for the test data
test_generator = test_datagen.flow_from_directory(
    test_data_dir,  # Specifies the directory containing the test data
    target_size=(28, 28),  # Resizes the images to 28x28 pixels
    batch_size=test_batch_size,  # Sets the batch size for the test data
    class_mode='categorical',  # Specifies that the labels should be one-hot encoded
    color_mode='grayscale',  # Specifies that the images are grayscale
    shuffle=True,  # Shuffles the test data
)
x_train, y_train = train_generator[0] # Retrieves the first batch of data and labels from the training generator and assigns them to x_train and y_train, respectively.
x_test, y_test = test_generator[0]

model = models.Sequential() 
# Creates a linear stack of layers for the model.
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))) 
# Adds a convolutional layer with 32 filters, each 3x3 in size, using ReLU activation. It expects input images of shape 28x28x1.
model.add(layers.MaxPooling2D((2, 2))) #Max pooling reduces the size of an image by keeping only the maximum value from each small region.
# Adds a max pooling layer with a 2x2 pool size, reducing the spatial dimensions.
model.add(layers.Flatten()) 
# Flattens the output from the previous layer into a 1D array.
model.add(layers.Dense(64, activation='relu')) 
# Adds a fully connected layer with 64 units and ReLU activation.
model.add(layers.Dense(10, activation='softmax')) 
# Adds an output layer with 10 units (for 10 classes) and softmax activation, providing probabilities for each class.

model.compile(optimizer='adam',#Adam optimizer adjusts the learning rate for each parameter individually to speed up training
              loss='categorical_crossentropy',#Categorical cross-entropy measures the difference between predicted probabilities and true labels 
              metrics=['accuracy']) 

model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))
test_loss, test_accuracy = model.evaluate(x_test, y_test)
print("Loss: ", test_loss)
print("Accuracy: ", test_accuracy)

n = 30 
plt.imshow(x_test[n])
predicted_value = model.predict(x_test)
print("Actual Number: ",np.argmax(y_test[n]))
print("Predicted Number: ", np.argmax(predicted_value[n]))
